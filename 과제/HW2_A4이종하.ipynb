{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MNIST 데이터 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [공통]\n",
    "1. 모델의 layer 개수, hidden node의 개수 제한 없음.\n",
    "2. activation function 또한 제한이 없음, \n",
    "   softmax함수의 경우에는 맨 끝단에만 사용.\n",
    "3. dropout, batch normalization의 경우 선택 사항임. \n",
    "   모델의 test_accuracy를 높이지 못한다면 굳이 사용할 필요 없음\n",
    "   \n",
    "### [MNIST]\n",
    "test_accuracy 99% 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: gpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"device: gpu\") if torch.cuda.is_available() else print(\"device: cpu\")\n",
    "# nvidia driver설치를 통한 gpu 인식 성공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter setting\n",
    "learning_rate = 1e-1\n",
    "epochs = 100\n",
    "# batch_size = 60000 # gradient descent\n",
    "# batch_size = 1 # stochastic gradient descent\n",
    "batch_size = 32 # mini-batch stochastic gradient descent\n",
    "act = nn.Tanh()\n",
    "h = 200\n",
    "display_step = 10\n",
    "dropout_rate = .2 # 1-% = 0.8만큼 사용 의미 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data):  60000\n",
      "len(test_data):  10000\n",
      "original data shape:  torch.Size([1, 28, 28])\n",
      "label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed data shape: torch.Size([32, 1, 28, 28])\n",
      "label: tensor([1, 1, 2, 1, 6, 7, 7, 1, 8, 0, 4, 1, 8, 0, 1, 5, 7, 4, 6, 6, 1, 8, 2, 4,\n",
      "        2, 3, 6, 6, 6, 2, 5, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "train_data = dataset.MNIST(\"./\", train = True, transform = transforms.ToTensor(), target_transform = None, download = True)\n",
    "test_data = dataset.MNIST(\"./\", train = False, transform = transforms.ToTensor(), target_transform = None, download = True)\n",
    "\n",
    "# check the data\n",
    "print('len(train_data): ', len(train_data))\n",
    "print('len(test_data): ', len(test_data))\n",
    "\n",
    "x_train, y_train = train_data[0]\n",
    "print('original data shape: ', x_train.shape)\n",
    "print('label: ', y_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "\n",
    "# Pre-process (batch, shuffle)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers = 1, drop_last = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 10000, shuffle = True, num_workers = 1, drop_last = True)\n",
    "\n",
    "# check the data \n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_target) = next(examples)\n",
    "\n",
    "print('processed data shape:', example_data.shape)\n",
    "print('label:', example_target)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(example_data[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, num_workers = 1, drop_last = True)\n",
    "\n",
    "# batchnorm + dropout in CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding =1), # 28 x 28\n",
    "            nn.BatchNorm2d(16), #batch norm\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(16, 32, 3, padding =1), # 14 x 14 \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2) # 7 x 7\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32*7*7,100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate), #drop out\n",
    "            nn.Linear(100,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        feature_extraction = self.feature_extraction(x)\n",
    "        flatten = feature_extraction.view(batch_size, -1)         \n",
    "        logit = self.classifier(flatten)\n",
    "        \n",
    "        return logit\n",
    "        \n",
    "model = CNN().to(device)\n",
    "model.train()\n",
    "\n",
    "# loss and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch loss: 0.16290855407714844\n",
      "10 epoch loss: 0.003077954053878784\n",
      "20 epoch loss: 0.024228066205978394\n",
      "30 epoch loss: 0.0020674467086791992\n",
      "40 epoch loss: 0.007800966501235962\n",
      "50 epoch loss: 0.005889728665351868\n",
      "60 epoch loss: 0.0023231953382492065\n",
      "70 epoch loss: 0.008546993136405945\n",
      "80 epoch loss: 0.0013611912727355957\n",
      "90 epoch loss: 9.959936141967773e-05\n",
      "Accuracy of the model: 0.9917868971824646\n"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "\n",
    "# train the model\n",
    "for i in range(epochs):\n",
    "    for index, [data, label] in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data)\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % display_step == 0:\n",
    "        print('{} epoch loss: {}'.format(i,loss))\n",
    "        loss_array.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "#test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "prediction_list = []\n",
    "label_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, [data, label] in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        output = model.forward(data)\n",
    "        _, prediction_index = torch.max(output, 1)\n",
    "        \n",
    "        prediction_list.append(prediction_index)\n",
    "        label_list.append(label)\n",
    "        \n",
    "        total += label.size(0)\n",
    "        correct += (prediction_index == label).sum().float()\n",
    "\n",
    "    print(\"Accuracy of the model: {}\".format(correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CIFAR10 데이터 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [공통]\n",
    "1. 모델의 layer 개수, hidden node의 개수 제한 없음.\n",
    "2. activation function 또한 제한이 없음, \n",
    "   softmax함수의 경우에는 맨 끝단에만 사용.\n",
    "3. dropout, batch normalization의 경우 선택 사항임. \n",
    "   모델의 test_accuracy를 높이지 못한다면 굳이 사용할 필요 없음\n",
    "   \n",
    "### [CIFAR10]\n",
    "test_accuracy 90% 이상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: gpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: gpu\") if torch.cuda.is_available() else print(\"device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameter setting\n",
    "learning_rate = 1e-2\n",
    "training_epochs = 200\n",
    "display_step = 10\n",
    "batch_size = 128\n",
    "validation_ratio = 0.1\n",
    "\n",
    "activation = nn.ReLU()\n",
    "max_pool = nn.MaxPool2d(2) # kerel size, stride size, padding size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data):  50000\n",
      "len(test_data):  10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compose data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# load data\n",
    "train_data = dataset.CIFAR10(\"./data\", train=True, transform=transform_train, target_transform=None, download=True)\n",
    "test_data = dataset.CIFAR10(\"./data\", train=False, transform=transform_test, target_transform=None, download=True)\n",
    "\n",
    "# check the data\n",
    "print(\"len(train_data): \", len(train_data))\n",
    "print(\"len(test_data): \", len(test_data))\n",
    "\n",
    "x_train, y_train = train_data[0]\n",
    "x_train = np.transpose(x_train, (1, 2, 0))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data 길이:  45000\n",
      "valid_data 길이:  5000\n"
     ]
    }
   ],
   "source": [
    "# split train date with validation set\n",
    "valid_size = int(len(train_data) * validation_ratio)\n",
    "train_data, valid_data = random_split(train_data, [len(train_data)-valid_size, valid_size])\n",
    "print('len(train_data): ', len(train_data))\n",
    "print('len(valid_data): ', len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  torch.Size([128, 3, 32, 32])\n",
      "label:  tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVpElEQVR4nO3df5DdVXnH8fdj2IALcfmx/NiGRGRFApMoWbeBTiIl0qSYOLM4AyiMko7BKIJIG4uAoyBoGyw/Cv2BBkSgQjRBJUxlLEyMpTDtQliBBBOUpbiJXBMWcaHuqAs8/eNenCV+n7Obu/dH4HxeM5m9+33uud+Tb/bJ9+557jnH3B0ReeN7U7M7ICKNoWQXyYSSXSQTSnaRTCjZRTKhZBfJxB4TaWxmJwHXApOAG919xRjPV52vBqbuPyWMub9SePyZ539Tr+7UTNtkC2Nvnf62MNayz36JV41+5IqvEwAjcezhxx9LnGv34O6FF9KqrbOb2STgp8ACYBvwEHC6u/8k0UbJXgMrzpgfxkZGhguPf35Nb726s0smJWKLpreEsa/96zfDWMe80xKv+vvgePF1AqAUx+yoqYlz7R6iZJ/I2/g5wJPu/pS7/x74FtAzgdcTkTqaSLJPBbaO+n5b5ZiI7IYm8jt70VuFP3qbbmbLgGUTOI+I1MBEkn0bMG3U94cCz+z8JHdfCawE/c4u0kwTeRv/EHCEmb3NzCYDHwLuqk23RKTWqr6zu/tLZnYu8B+UB1lvcvfHa9YzCT3VvzGMtba2Fx4/f3FX2Gbt9/vC2GCiHy8mYt3txSPrndOnh22GhobC2IMbnwhjPYsTHRmZXHy8b33YZO2aBxIv+Po1oTq7u98N3F2jvohIHekTdCKZULKLZELJLpIJJbtIJpTsIpmY0Gi8NEdUXgPoHSguXy2cH5fePrd8Vhh7YmN/fK6+LWHsU2efVXi8VIrbPLHx/jB275rrwlhnSzyBZo/hgeJzbYnLjZfcHpc201oTsZFELOp/WxWv9+uwhe7sIplQsotkQskukgklu0gmlOwimdBo/OvQtLZ41HfLcPHo+bTWeMR66ZU3xyfb8l9h6IovXBHGhgaKR7TbiCe7lDbG024GE6tIfan/ojB2R3C61Lh5aoJPWmcilhqNj0bd46pL3OYHYQvd2UUyoWQXyYSSXSQTSnaRTCjZRTKhZBfJhEpvu6mDE7Hn+uJJHF1BqWnpqfFkl4JFgf/gT486Pm4WV/NYekbxxJs7bo/7Pj1RaZrbFU8KSa1rNxhMalkXn2oC4n7QnijLdQTthhLlusHgH/q3wZp76M4ukg0lu0gmlOwimVCyi2RCyS6SCSW7SCbMvfq9Fs3sacqThF4GXnL37jGer40dx+nDs+JS2WfnxXO2ZnYEM8dG4jrZl9bE68y90BGXvAYH41lqM6cXt1v+/XjW2zvCCFx6cly66kjM6OsrFU+XW76+eG26scX/Lu84Y2WiXXyt+gdKhcdf7t9aeLzcjdnFx//nb/GhJ4t2WK5JnX2+u6e2BBOR3YDexotkYqLJ7sA9ZvawmS2rRYdEpD4m+jZ+rrs/Y2YHAfea2RZ3v2/0Eyr/Ceg/ApEmm9Cd3d2fqXzdAXwPmFPwnJXu3j3W4J2I1FfVyW5me5vZlFcfAwuBTbXqmIjUVtWlNzM7nPLdHMq/Dtzu7l8eo41Kb+O0bN7CMLY0MYHtyMH1hcfbEjPDOLZ4qyaAB/rjrZDW3nl7GIuKg3skpsp9vjee5fVnYQROj3e24rx4kl1Vus97NIx1tMdlyif6esPYQFDCbItmwwFHzir+S/d99X28+ItHa1t6c/engHdV215EGkulN5FMKNlFMqFkF8mEkl0kE0p2kUw0eMHJPYB9g5jm0ow2UIqvxzn3x/WkxcGijZc+G5eMIN5I7ZDrvhTGDmiNS0PHdhWXhk4471NhmxmfPieM/fWdW8LYV2tcXoO4ltfeHpcHN/XdE8YGS8+FsY72aYXHD+iIV+AcGgxmyr0U9093dpFMKNlFMqFkF8mEkl0kE0p2kUw0eDR+EhBNFtBo/Gg/6K9uiPmhh3cEkb0TreJY5/xTwljXxngUf2SoONZ/yx1hmwXz54ex03vj0fh/KB6YrtqhC+OKwchQvF4fI/GI++xZM8PYrK5ji1+uJV5rsKOz+N9s5Q/iNrqzi2RCyS6SCSW7SCaU7CKZULKLZELJLpKJBpfefgckShcyYXdfd2vh8UVXLo8b9f4wDA1tif+9FsxbFMY23fOjwuMPrI/XtBtOlF/vqXF5LS4BQ8/CeCLMloG4JDqnKy6vzZ23OIy1dxQuGRcv5AfMCnbDWjMlbqM7u0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZGLP0ZmY3Ae8Hdrj7zMqx/YFvA4cBTwOnufvz9evmG9PRidgLidiRiVj79+8vPP7nV30mbPPLxOs98b374uBwXCp7y0DxrLfWUrz90wWJraa2x72oyjmXfTMRjWfzdU2fEcZmHhuX7GZ1BeU14C1BiS2+UhCt/vfmRJvx3NlvBk7a6diFwDp3PwJYV/leRHZjYyZ7Zb/1X+10uAe4pfL4FuDkGvdLRGqs2t/ZD3b3EkDl60G165KI1EPdPy5rZsuAZfU+j4ikVXtn325mHQCVr9FaSLj7SnfvdvfuKs8lIjVQbbLfBSypPF4CrK1Nd0SkXsZTelsFnAC0m9k24BJgBbDazJYCA8Cp4ztdKxCVLmq+h09VTuw8I4yt67+9pueaMSOeedXRGk95+udZS8IYx55ZeLjnk71hk62JIs8Vn7w4jD1ViktlPXQUHi8RLxx5SBhJl94SE72Y03VecaAtmDYGHDkjLq/NaIlLaNNmxf2YkZjBFhX6Ek2qMmayu/vpQejEGvdFROpIn6ATyYSSXSQTSnaRTCjZRTKhZBfJRGMXnNzzzXBoUJ8YjkshlNbUtBt7dRbvrQUwNK+4ZASEa2UenDhXvCQjLNgyFMbaiGO0x+Urbry68HC8YxvckZjl9VwpXnDygrPODmOddwavOdgettlK8Yw9SM8Ag/g1o6t45OKjwjYdcUWUw0fiWGeiXUqtS2wR3dlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyURDS2977t3KW4+dXdyRlkQBYmRu4eGf3LkqbHLo9Lgcc8FZPWHs1s/s+job5yZiqfW6UgtHJktN99yZ7E+RaIFCgKWJWNupZ8XBzuJ/F4DhweI951qJp4adOT3uZV8pnnH44Ei88OU1lxXPApybqPSmVNms5qIKoCfa6M4ukgklu0gmlOwimVCyi2RCyS6SiYaOxu+9117Midb3Sqy5Vhoqns7Qemq0YhYc2xmPxrPm7jCUGm19Ljj+tUSbzydixydiqRHy1Mj6CYlYJDl/Y82NcezOeFZI66zgbxAvWwft94ah4cS8oL85K77KSxe/uzgQD+BXPzMlMUkmfZEbQ3d2kUwo2UUyoWQXyYSSXSQTSnaRTCjZRTIxnu2fbgLeD+xw95mVY5cCHwOerTztYneP61kVrXu2MLuzeI234dTUj2CSTOtIqtYR12ou6I0nVfw28Yq1dl8i9uNELDWBJlpr7rNjd2fXjZTi2Py/LD5eejJssn7gn8LYwoXxlKJLl18W92N9cPzyuMlg1Aa49Q8/8n/sucTidV9+ZnL8olWIsiXenGp8d/abgZMKjl/j7sdU/oyZ6CLSXGMmu7vfB/yqAX0RkTqayO/s55rZY2Z2k5ntV7MeiUhdVJvs11P+ZOkxQAm4KnqimS0zsw1mtuE3Lz5f5elEZKKqSnZ33+7uL7v7K8ANwJzEc1e6e7e7d+89RW8ARJqlqmQ3s9FD6h8ANtWmOyJSL+Mpva2iPJmq3cy2AZcAJ5jZMZSXvHoa+Ph4Tja5ZTLTO4rnbA0OJ8poQZ3hpfa41FHq7w1j1ZbX9qrx66W0Jaa2bZ0elykvvL/4OiY2taJ4lbZxmP6pOBZMbmSwL2zyy8T2Tz29S+JzXR+H4hLbv4dNUpPeFoV/MfhWKd6Wa+1fvSeM9dycOGENjZns7l40j/TrdeiLiNSRPkEnkgklu0gmlOwimVCyi2RCyS6SiYYuOPmmN02itXXfwlh7ot7REVSahkbiRSVLA3EZpFrVlNimJGKnJ2ZJtS0/L4yVOg4IY2cOF3/kYUFfYuHIap39/jjWHwUeCJuckpipOHsgMRXt8h/GsXD+YLziZCvxbL4ZxD9zCxIFzv6+1FKmf5KI1Y7u7CKZULKLZELJLpIJJbtIJpTsIplQsotkoqGltz1aoD2oTqSWjgwNxcvrtUcnAmiJp5RNGhkIYy+Pq1Ov9WIidsHy5WGs87x4/7LEMo90nBoE3r4gbtT/wcQrJnar60o0uygKxP2YnSi9pRYQhVT/o5JXPHsNUmXbuB8bE/PlFiyO/60bRXd2kUwo2UUyoWQXyYSSXSQTSnaRTDR0NH7yZJgWDIQ/lxhsHQzmLLQmJs/MnffuMHbiydGQNaxbE66KzQeDvj8YD+Dzv3GITVviUd/UtInUenKRVaV4AsoZiXZ9iW25Zgc7PKUltvmiJxFblYjFk1ri86VW3kuN/Me1kE9MT2zo9feJl2wQ3dlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXycR4tn+aBtwKHAK8Aqx092vNbH/g28BhlLeAOs3dk9u07gHhCl5t8XJszEzEqjG45BNhrHUg3p5oRlvxdJ27B+Jti1IuufH2MNZzw21VveZHLyre7+gbw9dV9XrnsyKM/SenJFpG5bDUJJNovTgYZk0YS23XFJfKUpsaxT8DwyyM+/HzA5M9abbx3NlfApa7+1HAccA5ZnY0cCGwzt2PANZVvheR3dSYye7uJXfvqzx+EdgMTKX8CYhbKk+7BTi5Xp0UkYnbpd/ZzewwYDbQCxzs7iUo/4cAHFTrzolI7Yw72c1sH+A7wPnu/sIutFtmZhvMbMPgs89W00cRqYFxJbuZtVBO9Nvc/buVw9vNrKMS7wB2FLV195Xu3u3u3e0H7t4DGCJvZGMmu5kZ5aHLze5+9ajQXcCSyuMlwNrad09EamU8s97mAh8BNprZI5VjFwMrgNVmthQYAOKpZBVGPAcpNReq1s5c/PYwNn3k78JY75qrC4/PTJzrvxOxRxOxu1fcEAdb4zX0vrHiC4lX3XX/wtNxsCvxTm04OL7lPYmzPRxGWpMz4qKTQfyTVbxNVtniuB9+WaLd7m3MZHf3+ynnaZETa9sdEakXfYJOJBNKdpFMKNlFMqFkF8mEkl0kEw1dcPL14ISTjwtjW9YXL/X4VB368dGLltXhVYtdvvonYWzmqY38IFS8SGg6Vo3Tavx6uz/d2UUyoWQXyYSSXSQTSnaRTCjZRTKhZBfJhEpvOxlJbPO1ak3xApHb69SXSHqGYPHkw5/76rBFPIdO3kh0ZxfJhJJdJBNKdpFMKNlFMqFkF8mERuP/iIeRTaXiLY26E8PjG4p3jALg8vnFE2sAto7EL9rWEe/H8ZXV18YnlKzpzi6SCSW7SCaU7CKZULKLZELJLpIJJbtIJsYsvZnZNOBW4BDgFWClu19rZpcCHwNe3Zr1Yne/u14dbZSWtmjzGwjnyLTHr3dwKY79eEtxKQ+gs2t+GPvKzSqvya4bT539JWC5u/eZ2RTgYTO7txK7xt2vrF/3RKRWxrPXWwkoVR6/aGabgan17piI1NYu/c5uZocBs4HeyqFzzewxM7vJzParcd9EpIbGnexmtg/wHeB8d38BuB7oBI6hfOe/Kmi3zMw2mNmGZ599tugpItIA40p2M2uhnOi3uft3Adx9u7u/7O6vADcAc4rauvtKd+929+4DD2zkhgMiMtqYyW5mBnwd2OzuV486PnoWxwdI724vIk02ntH4ucBHgI1m9kjl2MXA6WZ2DOVpYk8DH69LD3cjLwfHX2jtDNscOastjJWG4ylxPfN64o60xiGRyHhG4+8HiorPr/uaukhO9Ak6kUwo2UUyoWQXyYSSXSQTSnaRTGjByZ2s3RjH3rX4wsLj/3jlF8M2c2ZMDmOqoEkj6c4ukgklu0gmlOwimVCyi2RCyS6SCSW7SCbMPd7brOYnM2vcyUQy5e6Fq6bqzi6SCSW7SCaU7CKZULKLZELJLpIJJbtIJpTsIplQsotkQskukgklu0gmlOwimVCyi2RiPHu97WVmD5rZo2b2uJl9sXL8bWbWa2Y/M7Nvm1m82JqINN147uy/A97r7u+ivD3zSWZ2HHAFcI27HwE8DyytXzdFZKLGTHYv+7/Kty2VPw68F7ijcvwW4OS69FBEamK8+7NPquzgugO4F+gHfu3uL1Wesg2YWp8uikgtjCvZ3f1ldz8GOBSYAxxV9LSitma2zMw2mNmG6rspIhO1S6Px7v5r4EfAccC+ZvbqJhOHAs8EbVa6e7e7d0+koyIyMeMZjT/QzPatPH4z8BfAZmA9cErlaUuAtfXqpIhM3Jhr0JnZOykPwE2i/J/Dane/zMwOB74F7A/8GPiwu/9ujNfSGnQidRatQacFJ0XeYLTgpEjmlOwimVCyi2RCyS6SCSW7SCb2GPspNTUI/LzyuL3yfbOpH6+lfrzW660fb40CDS29vebEZht2h0/VqR/qRy790Nt4kUwo2UUy0cxkX9nEc4+mfryW+vFab5h+NO13dhFpLL2NF8lEU5LdzE4ysyfM7Ekzu7AZfaj042kz22hmjzRycQ0zu8nMdpjZplHH9jezeysLeN5rZvs1qR+XmtkvKtfkETNb1IB+TDOz9Wa2ubKo6acrxxt6TRL9aOg1qdsir+7e0D+Up8r2A4cDk4FHgaMb3Y9KX54G2ptw3uOBLmDTqGNfAS6sPL4QuKJJ/bgU+EyDr0cH0FV5PAX4KXB0o69Joh8NvSaAAftUHrcAvZQXjFkNfKhy/KvA2bvyus24s88BnnT3p9z995TnxPc0oR9N4+73Ab/a6XAP5XUDoEELeAb9aDh3L7l7X+Xxi5QXR5lKg69Joh8N5WU1X+S1Gck+Fdg66vtmLlbpwD1m9rCZLWtSH151sLuXoPxDBxzUxL6ca2aPVd7m1/3XidHM7DBgNuW7WdOuyU79gAZfk3os8tqMZC+aWN+sksBcd+8C3gecY2bHN6kfu5PrgU7KewSUgKsadWIz2wf4DnC+u7/QqPOOox8NvyY+gUVeI81I9m3AtFHfh4tV1pu7P1P5ugP4HuWL2izbzawDoPJ1RzM64e7bKz9orwA30KBrYmYtlBPsNnf/buVww69JUT+adU0q597lRV4jzUj2h4AjKiOLk4EPAXc1uhNmtreZTXn1MbAQ2JRuVVd3UV64E5q4gOeryVXxARpwTczMgK8Dm9396lGhhl6TqB+NviZ1W+S1USOMO402LqI80tkPfK5JfTicciXgUeDxRvYDWEX57eAI5Xc6S4EDgHXAzypf929SP/4N2Ag8RjnZOhrQj3mU35I+BjxS+bOo0dck0Y+GXhPgnZQXcX2M8n8sXxj1M/sg8CSwBthzV15Xn6ATyYQ+QSeSCSW7SCaU7CKZULKLZELJLpIJJbtIJpTsIplQsotk4v8BI1U9LxDPuRUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pre-process (batch, shuffle)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle=True, num_workers = 1, drop_last = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size, shuffle=True, num_workers = 1, drop_last = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, num_workers = 1, drop_last = True)\n",
    "\n",
    "# check the data\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_target) = next(examples)\n",
    "\n",
    "print(\"data shape: \", example_data.shape)\n",
    "print(\"label: \", example_target[0])\n",
    "\n",
    "check_image = example_data[0]\n",
    "check_image = np.transpose(check_image, (1, 2, 0))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(check_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # for initializing nn.Module (parent class)\n",
    "        self.feature_extraction = nn.Sequential( \n",
    "            nn.Conv2d(3, 64, 3, padding=1), # number of input channel, number of output channel, kernel size \n",
    "            nn.BatchNorm2d(64),                       # we can set stride size and padding size. if we do not set the these parameters, default value is 1, 0.\n",
    "            activation,\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation,\n",
    "            max_pool,\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            activation,\n",
    "            max_pool, \n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            activation,\n",
    "            max_pool,\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            activation,\n",
    "            max_pool,\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            activation,\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            activation,\n",
    "            max_pool,\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            activation,\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        extracted_feature = self.feature_extraction(x) \n",
    "        flatten = extracted_feature.view(batch_size, -1)\n",
    "        result = self.classifier(flatten)\n",
    "        return result\n",
    "    \n",
    "model = CNN().to(device)\n",
    "model.train()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pirl/anaconda3/envs/project1/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch loss: 2.111097812652588\n",
      "10 epoch loss: 0.8161717057228088\n",
      "20 epoch loss: 0.6456919312477112\n",
      "30 epoch loss: 0.4030783474445343\n",
      "40 epoch loss: 0.37220898270606995\n",
      "50 epoch loss: 0.3188883066177368\n",
      "60 epoch loss: 0.21205075085163116\n",
      "70 epoch loss: 0.2641332149505615\n",
      "80 epoch loss: 0.2145734280347824\n",
      "90 epoch loss: 0.1732998937368393\n",
      "100 epoch loss: 0.13840129971504211\n",
      "110 epoch loss: 0.16682401299476624\n",
      "120 epoch loss: 0.25426456332206726\n",
      "130 epoch loss: 0.1727197766304016\n",
      "140 epoch loss: 0.1420978605747223\n",
      "150 epoch loss: 0.14748823642730713\n",
      "160 epoch loss: 0.1512930989265442\n",
      "170 epoch loss: 0.08144273608922958\n",
      "180 epoch loss: 0.046271905303001404\n",
      "190 epoch loss: 0.08623021095991135\n"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "\n",
    "# train the model\n",
    "for i in range(training_epochs):\n",
    "    scheduler.step()\n",
    "    for index, [data, label] in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data)\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if i % display_step == 0:\n",
    "        print('{} epoch loss: {}'.format(i,loss))\n",
    "        loss_array.append(loss.cpu().detach().numpy())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.9098557829856873\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "    \n",
    "prediction_list = []\n",
    "label_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, [data, label] in enumerate(valid_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "            \n",
    "        output = model.forward(data)\n",
    "        _, prediction_index = torch.max(output, 1)\n",
    "            \n",
    "        prediction_list.append(prediction_index)\n",
    "        label_list.append(label)\n",
    "            \n",
    "        total += label.size(0)\n",
    "        correct += (prediction_index==label).sum().float()\n",
    "        \n",
    "    print(\"Accuracy of the model: {}\".format(correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
