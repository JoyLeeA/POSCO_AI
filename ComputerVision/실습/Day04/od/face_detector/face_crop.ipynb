{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20200527 Wensday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:50:03.112861Z",
     "start_time": "2019-04-02T09:50:02.805681Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T10:34:18.322674Z",
     "start_time": "2019-04-02T10:34:18.317680Z"
    }
   },
   "source": [
    "ssd 기반 face detection network 불러오기\n",
    "\n",
    "크롤링한 이미지 경로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:55:35.918529Z",
     "start_time": "2019-04-02T09:55:35.865671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "face_detecter_path = 'model/face_detector/'\n",
    "\n",
    "protoPath = face_detecter_path + \"deploy.prototxt\"\n",
    "modelPath = face_detecter_path + \"face_detect.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "train_data_path = 'dataset/train/'\n",
    "names = os.listdir(train_data_path+'1_raw_image/')\n",
    "imagePaths = [train_data_path+'1_raw_image/'+ name +'/'+filename for name in names for filename in os.listdir(train_data_path+'1_raw_image/'+name)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:55:36.544856Z",
     "start_time": "2019-04-02T09:55:36.526903Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/train/1_raw_image/Kim Hyesu/2. 2017032111004716800.jpeg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/32. cms_temp_stats_1459847453961594747.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/38. 2018050411254513799-540x686.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/40. 1490061676916617.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/3. o-1-570.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/65. a07480112ed5c81a71395b570e409e9b.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/39. 1fd5ab381344ab.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/16. 20180510114530_p_00_c_2_765.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/19. 143511303.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/9. 8873a46a33ed5fa0823262f53296b0c7.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/1. 181024_%ea%b9%80%ed%98%9c%ec%88%98.png',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/20. 250px-181022_%ea%b9%80%ed%98%9c%ec%88%98.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/36. 2018102621281036744_1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/10. 20161009074016_951791_600_900.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/31. 2018102201737_0.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/30. 84945304.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/22. 20180504114722349yjhx.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/29. 214_sq_01.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/60. n-1-628x314.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/44. 200408250500021_2.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/66. 2011-02-22_103b163b50.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/11. %ea%b9%80%ed%98%9c%ec%88%98.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/17. 548580750430180001.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/6. 1rzegrf5xd_1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/55. jyjy180525a5-1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/43. 48596_44891_413.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/23. negtethrbdnfbqbo1wfgndnjutw.jpg.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/18. 1500983521703294.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/12. 100141765.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/52. 2015092301403_0.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/45. 20151271431520185.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/57. 635c2cee9c4dd0017a44380ea2c87ae9.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/49. 20160129075647_809093_550_825.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/64. 162946_7436_727.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/62. 220739_116844_1123.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/54. %a4%b7_shdguq3588.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/50. 201703211123208957_7.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/15. kim_hye-soo%2c_2016_.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/7. bf.9959659.1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/35. 169365_201115_4858.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/41. b4c77a3be04e5b8eeda707fc1fbf26f3.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/48. gbyygvxye9x5636432362490196925.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/25. 201003051140161613151a_1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/5. 2013112300461_0.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/51. 1235374474_119666103728_20071203.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/4. 2018112401002051600157381.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/34. did1njfv4aac96e.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/26. 307553_46907_2324.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/46. 198024_197512_949.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/53. yn9c3z3829w12992jy66.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/24. 20160824_172256.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/33. 001a61832b2b0e04ffbf3a094f208acc.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/14. 2018112303729_0.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/63. kakaotalk_moim_5qsnttfhgbutt00x0wfsh3je2drwbz.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/27. 519719_400531_2957.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/61. 1oh2ytdl28_1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/42. 201703211123208957_6.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/37. 1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/47. 0126cb7146364a6f89d5cde8859c5bd7.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/21. 03.13831218.1.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/59. 517259_369302_4255.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/56. 15_08_21__5be918d5b2910[w680-].jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/.ipynb_checkpoints',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/13. 3c7c4d3cff276f931fa67fdbe88e3c67.jpg',\n",
       " 'dataset/train/1_raw_image/Kim Hyesu/58. 20171010115003241.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/12. e6c9e76d88b52c4dca43451910639b3d.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/33. ssi_20120131111616_v.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/31. 201810101038303943_l.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/8. 20152231424069173.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/50. ab1fb0653be2f3024963fbf054893406.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/44. htm_2013070313569c010c011.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/18. 2018071758111621.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/11. %ec%9d%b4%eb%af%b8%ec%a7%80_7.png',\n",
       " 'dataset/train/1_raw_image/Won Bin/27. i16518298936.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/40. 5a0182a-1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/38. 201506020005_61170009502357_1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/42. p0000013_70402[h800-].jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/17. 01.16427846.1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/5. 2018070316012237734_1530601280.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/49. 39978473_522125224901954_2385911224064802816_n.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/48. 00369872501_20100730.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/7. 658_sq_1450088341.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/20. 20130212164026_8069.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/13. hqdefault.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/23. 225px-won_bin.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/51. 4k6n7l7t7heud4mwg1ty.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/36. lkeqcjb_o.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/25. 1879fa384d86b9ec1a407c.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/41. nisi20121217_0007483537.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/35. 01.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/6. 20170328102502581.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/3. 201565491424075956.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/29. 55daa92ff24c6ace3dd84b2fe414cc6f.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/47. 20190215135155_1301450_1000_1500.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/14. 2015060808294983365_1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/19. 20121009_1349747203.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/24. 20190216182616740qpvq.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/1. 250px-won_bin_from_acrofan.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/22. 27083223_yjw_0973.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/4. image_readtop_2017_209104_1683689_0.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/45. 449177_100632_1627.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/46. 20180703115326847glwr.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/2. maxresdefault.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/28. 3453146_7wh.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/32. 201510201401_61180009976969_1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/21. 1404b9444f523e962f.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/52. 1s1xw3okxn_1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/10. n-thro-628x314.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/39. akr20090401082800005_01_i[h800-].jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/9. 51d9ee7fdfe19439b5edc024be31e0a0.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/34. a5b436ef6f74313d31abc1c0ed0aeee5.jpeg',\n",
       " 'dataset/train/1_raw_image/Won Bin/26. 037dd33e510bd8eb18.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/30. 400px-wonbin1.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/43. maxresdefault.jpg',\n",
       " 'dataset/train/1_raw_image/Won Bin/16. cd082c4a6af04c9d8c353aeff75724d7.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crop 이미지를 저장할 폴더가 없다면 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T09:56:45.639212Z",
     "start_time": "2019-04-02T09:56:45.634191Z"
    }
   },
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    if not os.path.exists(train_data_path+\"2_croped_image/\"+name):\n",
    "        os.makedirs(train_data_path+\"2_croped_image/\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼굴 detection 후 crop하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T14:50:29.335036Z",
     "start_time": "2019-04-01T14:49:23.182322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing image 1/115\n",
      "[INFO] processing image 2/115\n",
      "[INFO] processing image 3/115\n",
      "[INFO] processing image 4/115\n",
      "[INFO] processing image 5/115\n",
      "[INFO] processing image 6/115\n",
      "[INFO] processing image 7/115\n",
      "[INFO] processing image 8/115\n",
      "[INFO] processing image 9/115\n",
      "[INFO] processing image 10/115\n",
      "[INFO] processing image 11/115\n",
      "[INFO] processing image 12/115\n",
      "[INFO] processing image 13/115\n",
      "[INFO] processing image 14/115\n",
      "[INFO] processing image 15/115\n",
      "[INFO] processing image 16/115\n",
      "[INFO] processing image 17/115\n",
      "[INFO] processing image 18/115\n",
      "[INFO] processing image 19/115\n",
      "[INFO] processing image 20/115\n",
      "[INFO] processing image 21/115\n",
      "[INFO] processing image 22/115\n",
      "[INFO] processing image 23/115\n",
      "[INFO] processing image 24/115\n",
      "[INFO] processing image 25/115\n",
      "[INFO] processing image 26/115\n",
      "[INFO] processing image 27/115\n",
      "[INFO] processing image 28/115\n",
      "[INFO] processing image 29/115\n",
      "[INFO] processing image 30/115\n",
      "[INFO] processing image 31/115\n",
      "[INFO] processing image 32/115\n",
      "[INFO] processing image 33/115\n",
      "[INFO] processing image 34/115\n",
      "[INFO] processing image 35/115\n",
      "[INFO] processing image 36/115\n",
      "[INFO] processing image 37/115\n",
      "[INFO] processing image 38/115\n",
      "[INFO] processing image 39/115\n",
      "[INFO] processing image 40/115\n",
      "[INFO] processing image 41/115\n",
      "[INFO] processing image 42/115\n",
      "[INFO] processing image 43/115\n",
      "[INFO] processing image 44/115\n",
      "[INFO] processing image 45/115\n",
      "[INFO] processing image 46/115\n",
      "[INFO] processing image 47/115\n",
      "[INFO] processing image 48/115\n",
      "[INFO] processing image 49/115\n",
      "[INFO] processing image 50/115\n",
      "[INFO] processing image 51/115\n",
      "[INFO] processing image 52/115\n",
      "[INFO] processing image 53/115\n",
      "[INFO] processing image 54/115\n",
      "[INFO] processing image 55/115\n",
      "[INFO] processing image 56/115\n",
      "[INFO] processing image 57/115\n",
      "[INFO] processing image 58/115\n",
      "[INFO] processing image 59/115\n",
      "[INFO] processing image 60/115\n",
      "[INFO] processing image 61/115\n",
      "[INFO] processing image 62/115\n",
      "[INFO] processing image 63/115\n",
      "[INFO] processing image 64/115\n",
      "[INFO] processing image 65/115\n",
      "[INFO] processing image 66/115\n",
      "[INFO] processing image 67/115\n",
      "[INFO] processing image 68/115\n",
      "[INFO] processing image 69/115\n",
      "[INFO] processing image 70/115\n",
      "[INFO] processing image 71/115\n",
      "[INFO] processing image 72/115\n",
      "[INFO] processing image 73/115\n",
      "[INFO] processing image 74/115\n",
      "[INFO] processing image 75/115\n",
      "[INFO] processing image 76/115\n",
      "[INFO] processing image 77/115\n",
      "[INFO] processing image 78/115\n",
      "[INFO] processing image 79/115\n",
      "[INFO] processing image 80/115\n",
      "[INFO] processing image 81/115\n",
      "[INFO] processing image 82/115\n",
      "[INFO] processing image 83/115\n",
      "[INFO] processing image 84/115\n",
      "[INFO] processing image 85/115\n",
      "[INFO] processing image 86/115\n",
      "[INFO] processing image 87/115\n",
      "[INFO] processing image 88/115\n",
      "[INFO] processing image 89/115\n",
      "[INFO] processing image 90/115\n",
      "[INFO] processing image 91/115\n",
      "[INFO] processing image 92/115\n",
      "[INFO] processing image 93/115\n",
      "[INFO] processing image 94/115\n",
      "[INFO] processing image 95/115\n",
      "[INFO] processing image 96/115\n",
      "[INFO] processing image 97/115\n",
      "[INFO] processing image 98/115\n",
      "[INFO] processing image 99/115\n",
      "[INFO] processing image 100/115\n",
      "[INFO] processing image 101/115\n",
      "[INFO] processing image 102/115\n",
      "[INFO] processing image 103/115\n",
      "[INFO] processing image 104/115\n",
      "[INFO] processing image 105/115\n",
      "[INFO] processing image 106/115\n",
      "[INFO] processing image 107/115\n",
      "[INFO] processing image 108/115\n",
      "[INFO] processing image 109/115\n",
      "[INFO] processing image 110/115\n",
      "[INFO] processing image 111/115\n",
      "[INFO] processing image 112/115\n",
      "[INFO] processing image 113/115\n",
      "[INFO] processing image 114/115\n",
      "[INFO] processing image 115/115\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "    name = imagePath.split('/')[-2]\n",
    "\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    try:\n",
    "        image = imutils.resize(image, width=600)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "\n",
    "    imageBlob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300),\n",
    "        (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "    detector.setInput(imageBlob)\n",
    "    detections = detector.forward()\n",
    "\n",
    "    if len(detections) > 0:\n",
    "        i = np.argmax(detections[0, 0, :, 2])\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > 0.7: #0.7보다 크면 같은 인물이라고 인식\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            face = image[startY:endY, startX:endX]\n",
    "            (fH, fW) = face.shape[:2]\n",
    "\n",
    "            if fW < 20 or fH < 20:\n",
    "                continue\n",
    "                \n",
    "            cv2.imwrite(train_data_path+\"2_croped_image/\"+name+'/'+str(total)+'.jpg',face)\n",
    "            total +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "150"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
